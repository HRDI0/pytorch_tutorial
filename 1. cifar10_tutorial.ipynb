{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "Training a Classifier\n",
    "=====================\n",
    "\n",
    "This is it. You have seen how to define neural networks, compute loss and make\n",
    "updates to the weights of the network.\n",
    "\n",
    "Now you might be thinking,\n",
    "\n",
    "What about data?\n",
    "----------------\n",
    "\n",
    "Generally, when you have to deal with image, text, audio or video data,\n",
    "you can use standard python packages that load data into a numpy array.\n",
    "Then you can convert this array into a ``torch.*Tensor``.\n",
    "\n",
    "-  For images, packages such as Pillow, OpenCV are useful\n",
    "-  For audio, packages such as scipy and librosa\n",
    "-  For text, either raw Python or Cython based loading, or NLTK and\n",
    "   SpaCy are useful\n",
    "\n",
    "Specifically for vision, we have created a package called\n",
    "``torchvision``, that has data loaders for common datasets such as\n",
    "ImageNet, CIFAR10, MNIST, etc. and data transformers for images, viz.,\n",
    "``torchvision.datasets`` and ``torch.utils.data.DataLoader``.\n",
    "\n",
    "This provides a huge convenience and avoids writing boilerplate code.\n",
    "\n",
    "For this tutorial, we will use the CIFAR10 dataset.\n",
    "It has the classes: ‘airplane’, ‘automobile’, ‘bird’, ‘cat’, ‘deer’,\n",
    "‘dog’, ‘frog’, ‘horse’, ‘ship’, ‘truck’. The images in CIFAR-10 are of\n",
    "size 3x32x32, i.e. 3-channel color images of 32x32 pixels in size.\n",
    "\n",
    ".. figure:: /_static/img/cifar10.png\n",
    "   :alt: cifar10\n",
    "\n",
    "   cifar10\n",
    "\n",
    "\n",
    "Training an image classifier\n",
    "----------------------------\n",
    "\n",
    "We will do the following steps in order:\n",
    "\n",
    "1. Load and normalize the CIFAR10 training and test datasets using\n",
    "   ``torchvision``\n",
    "2. Define a Convolutional Neural Network\n",
    "3. Define a loss function\n",
    "4. Train the network on the training data\n",
    "5. Test the network on the test data\n",
    "\n",
    "1. Load and normalize CIFAR10\n",
    "^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
    "\n",
    "Using ``torchvision``, it’s extremely easy to load CIFAR10.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The output of torchvision datasets are PILImage images of range [0, 1].\n",
    "We transform them to Tensors of normalized range [-1, 1].\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-info\"><h4>Note</h4><p>If running on Windows and you get a BrokenPipeError, try setting\n",
    "    the num_worker of torch.utils.data.DataLoader() to 0.</p></div>\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- torchvision에서 제공하는 몇가지 데이터 셋중에 우리는 CIFR10을 이용해 모델을 작성해볼 것이다.\n",
    "- 위 코드는 torchvision에서 데이터셋을 다운로드하고 train, test dataloader를 만드는 과정이다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n"
     ]
    }
   ],
   "source": [
    "transform = transforms.Compose(\n",
    "    [transforms.ToTensor(),\n",
    "     transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))])\n",
    "\n",
    "batch_size = 2\n",
    "\n",
    "trainset = torchvision.datasets.CIFAR10(root='./data', train=True,\n",
    "                                        download=True, transform=transform)\n",
    "trainloader = torch.utils.data.DataLoader(trainset, batch_size=batch_size,\n",
    "                                          shuffle=True, num_workers=0)\n",
    "\n",
    "testset = torchvision.datasets.CIFAR10(root='./data', train=False,\n",
    "                                       download=True, transform=transform)\n",
    "testloader = torch.utils.data.DataLoader(testset, batch_size=batch_size,\n",
    "                                         shuffle=False, num_workers=0)\n",
    "\n",
    "classes = ('plane', 'car', 'bird', 'cat',\n",
    "           'deer', 'dog', 'frog', 'horse', 'ship', 'truck')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let us show some of the training images, for fun.\n",
    "\n",
    "- 우리는 로드한 데이터셋 이미지 몇개를 확인해 볼것이다.\n",
    "- 이때 pyplot를 활용해 이미지를 로드했을 때 오류가 발생하는데, 이는 세 가지 이유중 하나에 의해 발생한다.\n",
    "1. 라이브러리 충돌\n",
    "2. nomkl 미설치\n",
    "3. 너무 높은 numpy 버전"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "frog  plane\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "os.environ['KMP_DUPLICATE_LIB_OK']='True'\n",
    "#This is pyplot error solve code\n",
    "#why this code have pyplot error? -> reason is 1. library crash 2. nomkl library not install 3. Too high numpy version\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "# functions to show an image\n",
    "\n",
    "\n",
    "def imshow(img):\n",
    "    img = img / 2 + 0.5     # unnormalize\n",
    "    npimg = img.numpy()\n",
    "    plt.imshow(np.transpose(npimg, (1, 2, 0)))\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "# get some random training images\n",
    "dataiter = iter(trainloader)\n",
    "images, labels = dataiter.next()\n",
    "\n",
    "# show images\n",
    "imshow(torchvision.utils.make_grid(images))\n",
    "# print labels\n",
    "print(' '.join(f'{classes[labels[j]]:5s}' for j in range(batch_size)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2. Define a Convolutional Neural Network\n",
    "^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
    "Copy the neural network from the Neural Networks section before and modify it to\n",
    "take 3-channel images (instead of 1-channel images as it was defined).\n",
    "\n",
    "\n",
    "- 이미지가 RGB 3채널인것을 감안하며 신경망을 구성한다.\n",
    "- 튜토리얼에서 구성한 신경망으로 살펴보아 기본적인 CNN 신경망으로 보인다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "\n",
    "class Net(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.conv1 = nn.Conv2d(3, 6, 5)\n",
    "        self.pool = nn.MaxPool2d(2, 2)\n",
    "        self.conv2 = nn.Conv2d(6, 16, 5)\n",
    "        self.fc1 = nn.Linear(16 * 5 * 5, 120)\n",
    "        self.fc2 = nn.Linear(120, 84)\n",
    "        self.fc3 = nn.Linear(84, 10)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.pool(F.relu(self.conv1(x)))\n",
    "        x = self.pool(F.relu(self.conv2(x)))\n",
    "        x = torch.flatten(x, 1) # flatten all dimensions except batch\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = F.relu(self.fc2(x))\n",
    "        x = self.fc3(x)\n",
    "        return x\n",
    "\n",
    "\n",
    "net = Net()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3. Define a Loss function and optimizer\n",
    "^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
    "Let's use a Classification Cross-Entropy loss and SGD with momentum.\n",
    "\n",
    "- 이제 학습을 진행하기 위해 손실함수와 파라미터 조정을 위한 옵티마이저를 설정한다.\n",
    "- 손실 함수는 크로스엔트로피, 옵티마이저는 SGD로 학습률은 0.001, 관성은 0.9이다.)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.optim as optim\n",
    "\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.SGD(net.parameters(), lr=0.001, momentum=0.9)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "4. Train the network\n",
    "^^^^^^^^^^^^^^^^^^^^\n",
    "\n",
    "This is when things start to get interesting.\n",
    "We simply have to loop over our data iterator, and feed the inputs to the\n",
    "network and optimize.\n",
    "\n",
    "- 이제 작성한 신경망을 학습시킨다.\n",
    "- 아래의 코드의 경우 배치 단위만큼씩 진행하며 2회 반복 학습한다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1,  2000] loss: 2.272\n",
      "[1,  4000] loss: 2.020\n",
      "[1,  6000] loss: 1.855\n",
      "[1,  8000] loss: 1.720\n",
      "[1, 10000] loss: 1.656\n",
      "[1, 12000] loss: 1.612\n",
      "[1, 14000] loss: 1.565\n",
      "[1, 16000] loss: 1.543\n",
      "[1, 18000] loss: 1.491\n",
      "[1, 20000] loss: 1.470\n",
      "[1, 22000] loss: 1.445\n",
      "[1, 24000] loss: 1.430\n",
      "[2,  2000] loss: 1.366\n",
      "[2,  4000] loss: 1.348\n",
      "[2,  6000] loss: 1.363\n",
      "[2,  8000] loss: 1.344\n",
      "[2, 10000] loss: 1.382\n",
      "[2, 12000] loss: 1.320\n",
      "[2, 14000] loss: 1.339\n",
      "[2, 16000] loss: 1.333\n",
      "[2, 18000] loss: 1.299\n",
      "[2, 20000] loss: 1.301\n",
      "[2, 22000] loss: 1.271\n",
      "[2, 24000] loss: 1.295\n",
      "Finished Training\n"
     ]
    }
   ],
   "source": [
    "for epoch in range(2):  # loop over the dataset multiple times\n",
    "\n",
    "    running_loss = 0.0\n",
    "    for i, data in enumerate(trainloader, 0):\n",
    "        # get the inputs; data is a list of [inputs, labels]\n",
    "        inputs, labels = data\n",
    "\n",
    "        # zero the parameter gradients\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        # forward + backward + optimize\n",
    "        outputs = net(inputs)\n",
    "        loss = criterion(outputs, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        # print statistics\n",
    "        running_loss += loss.item()\n",
    "        if i % 2000 == 1999:    # print every 2000 mini-batches\n",
    "            print(f'[{epoch + 1}, {i + 1:5d}] loss: {running_loss / 2000:.3f}')\n",
    "            running_loss = 0.0\n",
    "\n",
    "print('Finished Training')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's quickly save our trained model:\n",
    "\n",
    "- 모델을 외부에 저장한다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "PATH = './cifar_net.pth'\n",
    "torch.save(net.state_dict(), PATH)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "See `here <https://pytorch.org/docs/stable/notes/serialization.html>`_\n",
    "for more details on saving PyTorch models.\n",
    "\n",
    "5. Test the network on the test data\n",
    "^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
    "\n",
    "We have trained the network for 2 passes over the training dataset.\n",
    "But we need to check if the network has learnt anything at all.\n",
    "\n",
    "We will check this by predicting the class label that the neural network\n",
    "outputs, and checking it against the ground-truth. If the prediction is\n",
    "correct, we add the sample to the list of correct predictions.\n",
    "\n",
    "Okay, first step. Let us display an image from the test set to get familiar.\n",
    "\n",
    "- 이제 신경망을 테스트할 시간이다.\n",
    "- 이런 저런 말이 많지만 제대로 학습된 모델이 외부에 저장되었는지 확인해야한다는 내용이다.\n",
    "- 외부에 저장한 모델 파일의 대한 자세한 내용은 위 링크에 있다.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GroundTruth:  cat   ship \n"
     ]
    }
   ],
   "source": [
    "dataiter = iter(testloader)\n",
    "images, labels = dataiter.next()\n",
    "\n",
    "# print images\n",
    "imshow(torchvision.utils.make_grid(images))\n",
    "print('GroundTruth: ', ' '.join(f'{classes[labels[j]]:5s}' for j in range(2)))\n",
    "# edit print repeat 4 to 2\n",
    "# why?1. we edit batch_size in second code block. \n",
    "# why?2. Because I mistook the dead kernel error for a batch size problem, not pyplot."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, let's load back in our saved model (note: saving and re-loading the model\n",
    "wasn't necessary here, we only did it to illustrate how to do so):\n",
    "\n",
    "- 외부에 저장된 모델이 제대로 되어 있는 건지 확인 해본다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "net = Net()\n",
    "net.load_state_dict(torch.load(PATH))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Okay, now let us see what the neural network thinks these examples above are:\n",
    "\n",
    "- 위 이미지를 예로 테스트 검증을 진행해본다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "outputs = net(images)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The outputs are energies for the 10 classes.\n",
    "The higher the energy for a class, the more the network\n",
    "thinks that the image is of the particular class.\n",
    "So, let's get the index of the highest energy:\n",
    "\n",
    "- 위의 lable 값과 마찬가지로 예측값이 도출되었다. 이로서 모델의 성능과 정상작동을 확인했다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicted:  cat   ship \n"
     ]
    }
   ],
   "source": [
    "_, predicted = torch.max(outputs, 1)\n",
    "\n",
    "print('Predicted: ', ' '.join(f'{classes[predicted[j]]:5s}'\n",
    "                              for j in range(2)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The results seem pretty good.\n",
    "\n",
    "Let us look at how the network performs on the whole dataset.\n",
    "\n",
    "- 이제 전체 테스트 데이터에 대해 검증을 진행해본다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of the network on the 10000 test images: 53 %\n"
     ]
    }
   ],
   "source": [
    "correct = 0\n",
    "total = 0\n",
    "# since we're not training, we don't need to calculate the gradients for our outputs\n",
    "with torch.no_grad():\n",
    "    for data in testloader:\n",
    "        images, labels = data\n",
    "        # calculate outputs by running images through the network\n",
    "        outputs = net(images)\n",
    "        # the class with the highest energy is what we choose as prediction\n",
    "        _, predicted = torch.max(outputs.data, 1)\n",
    "        total += labels.size(0)\n",
    "        correct += (predicted == labels).sum().item()\n",
    "\n",
    "print(f'Accuracy of the network on the 10000 test images: {100 * correct // total} %')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "That looks way better than chance, which is 10% accuracy (randomly picking\n",
    "a class out of 10 classes).\n",
    "Seems like the network learnt something.\n",
    "\n",
    "Hmmm, what are the classes that performed well, and the classes that did\n",
    "not perform well:\n",
    "\n",
    "- 각 클래스별(분류별) 정확도를 알아보자."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy for class: plane is 55.9 %\n",
      "Accuracy for class: car   is 91.2 %\n",
      "Accuracy for class: bird  is 44.7 %\n",
      "Accuracy for class: cat   is 52.6 %\n",
      "Accuracy for class: deer  is 35.7 %\n",
      "Accuracy for class: dog   is 42.0 %\n",
      "Accuracy for class: frog  is 58.4 %\n",
      "Accuracy for class: horse is 51.7 %\n",
      "Accuracy for class: ship  is 65.9 %\n",
      "Accuracy for class: truck is 32.5 %\n"
     ]
    }
   ],
   "source": [
    "# prepare to count predictions for each class\n",
    "correct_pred = {classname: 0 for classname in classes}\n",
    "total_pred = {classname: 0 for classname in classes}\n",
    "\n",
    "# again no gradients needed\n",
    "with torch.no_grad():\n",
    "    for data in testloader:\n",
    "        images, labels = data\n",
    "        outputs = net(images)\n",
    "        _, predictions = torch.max(outputs, 1)\n",
    "        # collect the correct predictions for each class\n",
    "        for label, prediction in zip(labels, predictions):\n",
    "            if label == prediction:\n",
    "                correct_pred[classes[label]] += 1\n",
    "            total_pred[classes[label]] += 1\n",
    "\n",
    "\n",
    "# print accuracy for each class\n",
    "for classname, correct_count in correct_pred.items():\n",
    "    accuracy = 100 * float(correct_count) / total_pred[classname]\n",
    "    print(f'Accuracy for class: {classname:5s} is {accuracy:.1f} %')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Okay, so what next?\n",
    "\n",
    "How do we run these neural networks on the GPU?\n",
    "\n",
    "Training on GPU\n",
    "----------------\n",
    "Just like how you transfer a Tensor onto the GPU, you transfer the neural\n",
    "net onto the GPU.\n",
    "\n",
    "Let's first define our device as the first visible cuda device if we have\n",
    "CUDA available:\n",
    "\n",
    "- 우리는 이제 gpu를 사용해 모델을 학습하고 검증해볼 것이다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda:0\n"
     ]
    }
   ],
   "source": [
    "device = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "# Assuming that we are on a CUDA machine, this should print a CUDA device:\n",
    "\n",
    "print(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The rest of this section assumes that ``device`` is a CUDA device.\n",
    "\n",
    "Then these methods will recursively go over all modules and convert their\n",
    "parameters and buffers to CUDA tensors:\n",
    "\n",
    ".. code:: python\n",
    "\n",
    "    net.to(device)\n",
    "\n",
    "\n",
    "Remember that you will have to send the inputs and targets at every step\n",
    "to the GPU too:\n",
    "\n",
    ".. code:: python\n",
    "\n",
    "        inputs, labels = data[0].to(device), data[1].to(device)\n",
    "\n",
    "Why don't I notice MASSIVE speedup compared to CPU? Because your network\n",
    "is really small.\n",
    "\n",
    "**Exercise:** Try increasing the width of your network (argument 2 of\n",
    "the first ``nn.Conv2d``, and argument 1 of the second ``nn.Conv2d`` –\n",
    "they need to be the same number), see what kind of speedup you get.\n",
    "\n",
    "**Goals achieved**:\n",
    "\n",
    "- Understanding PyTorch's Tensor library and neural networks at a high level.\n",
    "- Train a small neural network to classify images\n",
    "\n",
    "Training on multiple GPUs\n",
    "-------------------------\n",
    "If you want to see even more MASSIVE speedup using all of your GPUs,\n",
    "please check out :doc:`data_parallel_tutorial`.\n",
    "\n",
    "Where do I go next?\n",
    "-------------------\n",
    "\n",
    "-  :doc:`Train neural nets to play video games </intermediate/reinforcement_q_learning>`\n",
    "-  `Train a state-of-the-art ResNet network on imagenet`_\n",
    "-  `Train a face generator using Generative Adversarial Networks`_\n",
    "-  `Train a word-level language model using Recurrent LSTM networks`_\n",
    "-  `More examples`_\n",
    "-  `More tutorials`_\n",
    "-  `Discuss PyTorch on the Forums`_\n",
    "-  `Chat with other users on Slack`_\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 새로운 모델을 구축하고 매개변수 최적화를 거쳐 정확도를 올려보자."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda:0\n"
     ]
    }
   ],
   "source": [
    "device = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "# Assuming that we are on a CUDA machine, this should print a CUDA device:\n",
    "\n",
    "print(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n"
     ]
    }
   ],
   "source": [
    "transform = transforms.Compose(\n",
    "    [transforms.ToTensor(),\n",
    "     transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))])\n",
    "\n",
    "batch_size = 2\n",
    "\n",
    "trainset = torchvision.datasets.CIFAR10(root='./data', train=True,\n",
    "                                        download=True, transform=transform)\n",
    "trainloader = torch.utils.data.DataLoader(trainset, batch_size=batch_size,\n",
    "                                          shuffle=True, num_workers=0)\n",
    "\n",
    "testset = torchvision.datasets.CIFAR10(root='./data', train=False,\n",
    "                                       download=True, transform=transform)\n",
    "testloader = torch.utils.data.DataLoader(testset, batch_size=batch_size,\n",
    "                                         shuffle=False, num_workers=0)\n",
    "\n",
    "classes = ('plane', 'car', 'bird', 'cat',\n",
    "           'deer', 'dog', 'frog', 'horse', 'ship', 'truck')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([2, 3, 32, 32])"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataiter = iter(trainloader)\n",
    "images, labels = dataiter.next()\n",
    "images.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "class Net(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        \n",
    "        #torch.nn.Conv2d(in_channels, out_channels, kernel_size, \n",
    "        #stride=1, padding=0, dilation=1, groups=1, bias=True, padding_mode='zeros)\n",
    "        self.mpool = nn.MaxPool2d(kernel_size=3, stride=2)\n",
    "        self.con1 = nn.Conv2d(3, 64, kernel_size=11, stride=4, padding=2)\n",
    "        self.con2 = nn.Conv2d(64, 192, kernel_size=5, padding=2)\n",
    "        \n",
    "        self.avgpool = nn.AdaptiveAvgPool2d((3, 3))\n",
    "        \n",
    "        self.classifier = nn.Sequential(\n",
    "            nn.Dropout(0.2),\n",
    "            nn.Linear(192 * 3 * 3, 1920),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Dropout(0.2),\n",
    "            nn.Linear(1920,10),\n",
    "        )\n",
    "\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.mpool(F.relu(self.con1(x)))\n",
    "        x = self.mpool(F.relu(self.con2(x)))\n",
    "        x = self.avgpool(x)\n",
    "        x = torch.flatten(x, 1)\n",
    "        x = self.classifier(x)\n",
    "        return x\n",
    "\n",
    "\n",
    "net = Net()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Net(\n",
       "  (mpool): MaxPool2d(kernel_size=3, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "  (con1): Conv2d(3, 64, kernel_size=(11, 11), stride=(4, 4), padding=(2, 2))\n",
       "  (con2): Conv2d(64, 192, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2))\n",
       "  (avgpool): AdaptiveAvgPool2d(output_size=(3, 3))\n",
       "  (classifier): Sequential(\n",
       "    (0): Dropout(p=0.2, inplace=False)\n",
       "    (1): Linear(in_features=1728, out_features=1920, bias=True)\n",
       "    (2): ReLU(inplace=True)\n",
       "    (3): Dropout(p=0.2, inplace=False)\n",
       "    (4): Linear(in_features=1920, out_features=10, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "net.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.optim as optim\n",
    "\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.SGD(net.parameters(), lr=0.001, momentum=0.8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1,  2000] loss: 2.070\n",
      "[1,  4000] loss: 1.821\n",
      "[1,  6000] loss: 1.693\n",
      "[1,  8000] loss: 1.632\n",
      "[1, 10000] loss: 1.577\n",
      "[1, 12000] loss: 1.536\n",
      "[1, 14000] loss: 1.500\n",
      "[1, 16000] loss: 1.451\n",
      "[1, 18000] loss: 1.426\n",
      "[1, 20000] loss: 1.411\n",
      "[1, 22000] loss: 1.380\n",
      "[1, 24000] loss: 1.362\n",
      "[2,  2000] loss: 1.295\n",
      "[2,  4000] loss: 1.282\n",
      "[2,  6000] loss: 1.277\n",
      "[2,  8000] loss: 1.273\n",
      "[2, 10000] loss: 1.276\n",
      "[2, 12000] loss: 1.279\n",
      "[2, 14000] loss: 1.234\n",
      "[2, 16000] loss: 1.254\n",
      "[2, 18000] loss: 1.218\n",
      "[2, 20000] loss: 1.233\n",
      "[2, 22000] loss: 1.211\n",
      "[2, 24000] loss: 1.182\n",
      "[3,  2000] loss: 1.148\n",
      "[3,  4000] loss: 1.103\n",
      "[3,  6000] loss: 1.154\n",
      "[3,  8000] loss: 1.165\n",
      "[3, 10000] loss: 1.107\n",
      "[3, 12000] loss: 1.095\n",
      "[3, 14000] loss: 1.134\n",
      "[3, 16000] loss: 1.111\n",
      "[3, 18000] loss: 1.118\n",
      "[3, 20000] loss: 1.123\n",
      "[3, 22000] loss: 1.106\n",
      "[3, 24000] loss: 1.081\n",
      "Finished Training\n"
     ]
    }
   ],
   "source": [
    "for epoch in range(3):  # loop over the dataset multiple times\n",
    "\n",
    "    running_loss = 0.0\n",
    "    for i, data in enumerate(trainloader, 0):\n",
    "        # get the inputs; data is a list of [inputs, labels]\n",
    "        inputs, labels = data[0].to(device), data[1].to(device)\n",
    "        # zero the parameter gradients\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        # forward + backward + optimize\n",
    "        outputs = net(inputs)\n",
    "        loss = criterion(outputs, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        # print statistics\n",
    "        running_loss += loss.item()\n",
    "        if i % 2000 == 1999:    # print every 2000 mini-batches\n",
    "            print(f'[{epoch + 1}, {i + 1:5d}] loss: {running_loss / 2000:.3f}')\n",
    "            running_loss = 0.0\n",
    "\n",
    "print('Finished Training')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "PATH = './cifar_net_gpu_custom.pth'\n",
    "torch.save(net.state_dict(), PATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 87,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "net = Net()\n",
    "net.load_state_dict(torch.load(PATH))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Net(\n",
       "  (mpool): MaxPool2d(kernel_size=3, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "  (con1): Conv2d(3, 64, kernel_size=(11, 11), stride=(4, 4), padding=(2, 2))\n",
       "  (con2): Conv2d(64, 192, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2))\n",
       "  (avgpool): AdaptiveAvgPool2d(output_size=(3, 3))\n",
       "  (classifier): Sequential(\n",
       "    (0): Dropout(p=0.2, inplace=False)\n",
       "    (1): Linear(in_features=1728, out_features=1920, bias=True)\n",
       "    (2): ReLU(inplace=True)\n",
       "    (3): Dropout(p=0.2, inplace=False)\n",
       "    (4): Linear(in_features=1920, out_features=10, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 88,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "net.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of the network on the 10000 test images: 60 %\n"
     ]
    }
   ],
   "source": [
    "correct = 0\n",
    "total = 0\n",
    "# since we're not training, we don't need to calculate the gradients for our outputs\n",
    "with torch.no_grad():\n",
    "    for data in testloader:\n",
    "        images, labels = data[0].to(device), data[1].to(device)\n",
    "        # calculate outputs by running images through the network\n",
    "        outputs = net(images)\n",
    "        # the class with the highest energy is what we choose as prediction\n",
    "        _, predicted = torch.max(outputs.data, 1)\n",
    "        total += labels.size(0)\n",
    "        correct += (predicted == labels).sum().item()\n",
    "\n",
    "print(f'Accuracy of the network on the 10000 test images: {100 * correct // total} %')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "torch1.7",
   "language": "python",
   "name": "torch1.7"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
